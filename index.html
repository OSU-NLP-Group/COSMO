<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
    <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
    <meta property="og:url" content="URL OF THE WEBSITE" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />


    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>COSMO</title>
    <!-- <link rel="icon" type="image/x-icon" href="static/images/mammoth_icon.png"> -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="static/js/jquery.min.js"></script>
    <script src="static/js/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>

    <link rel="stylesheet" type="text/css" href="static/css/jquery.dataTables.css">
    <script type="text/javascript" charset="utf8" src="static/js/jquery-3.5.1.js"></script>
    <script type="text/javascript" charset="utf8" src="static/js/jquery.dataTables.js"></script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Bringing Back the Context: Camera Trap Species Identification as Link Prediction on Multimodal Knowledge Graphs</h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            <span class="author-block">
                            <a href="https://vardaan123.github.io/" target="_blank">Vardaan Pahuja</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                            <a href="https://www.linkedin.com/in/eddy-luo-aa02b5242/" target="_blank">Weidi Luo</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                            <a href="https://entslscheia.github.io/" target="_blank">Yu Gu</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                            <a href="https://andytu28.github.io/" target="_blank">Cheng-Hao Tu</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                            <a href="https://sites.google.com/view/hongyouc/" target="_blank">Hong-You Chen</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                            <a href="https://cse.osu.edu/people/berger-wolf.1" target="_blank">Tanya Berger-Wolf</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                            <a href="https://www.cs.rpi.edu/~stewart/" target="_blank">Charles Stewart</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                            <a href="https://geography.wisc.edu/staff/gao-song/" target="_blank">Song Gao</a><sup>3</sup>,
                            </span>
                            <span class="author-block">
                            <a href="https://sites.google.com/view/wei-lun-harry-chao" target="_blank">Wei-Lun Chao</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                            <a href="https://ysu1989.github.io/" target="_blank">Yu Su</a><sup>1</sup>,
                            </span>
                        </div>


                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                    <sup>1</sup>The Ohio State University,
                    <sup>2</sup>Rensselaer Polytechnic Institute,<br> 
                    <sup>3</sup>University of Wisconsin-Madison 
                            <!-- <span class="author-block"><a href="mailto:pahuja.9@osu.edu">pahuja.9@osu.edu</a> -->

                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">

                                <!-- Github link -->
                                <span class="link-block">
                      <a href="https://github.com/OSU-NLP-Group/COSMO" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                                <span>Code</span>
                                </a>
                                </span>

                                <!-- ArXiv abstract Link -->
                                <span class="link-block">
                    <a href="https://arxiv.org/pdf/2401.00608.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                                <span>arXiv</span>
                                </a>
                                </span>

                    <!-- Demo link -->
                                <span class="link-block">
                      <a href="https://07e272abc4ef9005fc.gradio.live" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <!-- <span class="icon"> -->
                        <!-- <i class="fab fa-github"></i> -->
                      <!-- </span> -->
                                <span>Demo</span>
                                </a>
                                </span>

                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>



    <!-- Paper abstract -->
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h2 class="title is-3">Abstract</h2>
                        <div class="content has-text-justified">
                            <p>
                              Camera traps are valuable tools in animal ecology for biodiversity monitoring and conservation.
                              However, challenges like poor generalization to deployment at new unseen locations limit their practical application.
                              Images are naturally associated with heterogeneous forms of context possibly in different modalities.
                              In this work, we leverage the structured context associated with the camera trap images to improve out-of-distribution generalization for the task of species identification in camera traps.
                              For example, a photo of a wild animal may be associated with information about where and when it was taken, as well as structured biology knowledge about the animal species. 
                              While typically overlooked by existing work, bringing back such context offers several potential benefits for better image understanding, such as addressing data scarcity and enhancing generalization.
                              However, effectively integrating such heterogeneous context into the visual domain is a challenging problem.
                              To address this, we propose a novel framework that reformulates species classification as link prediction in a multimodal knowledge graph (KG).
                              This framework seamlessly integrates various forms of multimodal context for visual recognition.
                              We apply this framework for out-of-distribution species classification on the iWildCam2020-WILDS and Snapshot Mountain Zebra datasets and achieve competitive performance with state-of-the-art approaches. Furthermore, our framework successfully incorporates biological taxonomy for improved generalization and enhances sample efficiency for recognizing under-represented species.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->



    <!-- Image carousel -->
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <!-- <div class="column is-four-fifths"> -->
                        <div class="item">
                            <!-- Your image here -->
                            <img src="static/images/mmkg_model_combined.png" alt="Overview of COSMO framework" />
                            <h2 class="subtitle">
                                <b>Overview of our framework COSMO</b>. <b><i>Left</b></i>: Our multimodal knowledge graph for camera traps and wildlife. Photos from
camera traps are jointly represented in the KG with contextual information such as time, location, and structured biology taxonomy. <b><i>Right</b></i>: In our formulation of species classification as link prediction, the plausibility score ψ(s, r, o) of each (subject, relation, object) triple is computed using a KGE model (<i>e.g.</i>, DistMult), where the subject, relation, and object are all first embedded into a vector space. 
                            </h2>
                        </div>
                    <!-- </div> -->
                </div>
            </div>
        </div>
    </section>
    <!-- End image carousel -->


    <section class="hero is-small">
        <div class="hero-body">
            <div class="container  is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Overall Results</h2>
                        <br>
                        <div class="item">
                            <img src="static/images/iwildcam_results_table.png" alt="Species Classification results on iWildCam2020-WILDS (OOD) dataset" />
                            <p>
                                <b>Species Classification results on iWildCam2020-WILDS (OOD) dataset</b>. The first baseline in the second section shows the
                                no-context baseline that uses only image-species labels as KG edges. All models use a pre-trained ResNet-50 as image encoder. Parentheses show standard deviation across 3 random seeds. Missing values are denoted by –.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero is-small">
        <div class="hero-body">
            <div class="container  is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column is-three-fifths">
                        <!-- <h2 class="title is-3">Overall Results</h2> -->
                        <div class="item">
                            <img src="static/images/snapshot_mountain_zebra_results_table.png" alt="Species Classification results on Snapshot Mountain Zebra dataset" />
                            <p>
                                <b>Species Classification results on Snapshot Mountain Zebra dataset.</b>
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <section class="hero is-small">
        <div class="hero-body">
            <div class="container  is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Spatiotemporal attributes give a prior for species distribution</h2>
                        <div class="item">
                            <img src="static/images/correlation_analysis.png" alt="Spatiotemporal attributes give a prior for species distribution" />
                            <h2 class="subtitle">
                                <b>(a):</b> Species probabilities conditioned on day/night for the 10 most frequent species in the
                                training set (iWildCam2020-WILDS). Animal species demonstrate distinct temporal
                                preferences for their daily activities, as evidenced by the contrasting probabilities
                                observed during day and night. <b>(b):</b> Each color square shows the distance between
                                the corresponding training hour slot on x-axis and validation hour slot on y-axis. The
                                correlation peaks for day-day and night-night hour slots. <b>(c):</b> Plot of location GPS
                                coordinates for training and validation splits (iWildCam2020-WILDS). The coordinates
                                can be grouped into six clusters. Most coordinates exhibit an overlap with their
                                respective cluster centroids at this visualization scale. <b>(d):</b> Each color square shows
                                the distance between the corresponding validation cluster centroid on x-axis and the
                                training cluster centroid on y-axis. The correlation peaks along the diagonal.
                            </h2>
                            
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>



    <!-- BibTex citation -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">Citation</h2>
            <!-- Please cite our paper if you use our code, data, model or results: -->
            <!-- <br> -->
            <pre><code>@article{pahuja2023bringing,
  title={Bringing Back the Context: Camera Trap Species Identification as Link Prediction on Multimodal Knowledge Graphs},
  author={Pahuja, Vardaan and Luo, Weidi and Gu, Yu and Tu, Cheng-Hao and Chen, Hong-You and Berger-Wolf, Tanya and Stewart, Charles and Gao, Song and Chao, Wei-Lun and Su, Yu},
  journal={arXiv preprint arXiv:2401.00608},
  year={2023}
}
</code></pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">

                        <p>
                            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a>                            project page. You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"
                                target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>
<style>
    .buttonGroup {
        text-align: center;
    }
    
    .buttonGroup>button {
        padding: 15px;
        color: white;
        background-color: #363636;
        border-radius: 5px;
    }
    
    .buttonGroup>button:hover {
        box-shadow: 5px;
    }
</style>

</html>
